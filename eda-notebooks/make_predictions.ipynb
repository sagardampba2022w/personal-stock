{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f20f6a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Stock Prediction Decision Making Notebook\n",
      "==================================================\n",
      "✅ Paths configured:\n",
      "   Project root: /Users/sagardhal/Desktop/Practice/personal-stock\n",
      "   App code: /Users/sagardhal/Desktop/Practice/personal-stock/app\n",
      "   Artifacts: /Users/sagardhal/Desktop/Practice/personal-stock/artifacts\n",
      "   Data: /Users/sagardhal/Desktop/Practice/personal-stock/data\n"
     ]
    }
   ],
   "source": [
    "# Stock Prediction Decision Making Notebook\n",
    "# Interactive notebook for making daily trading decisions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "TOP_N_PICKS = 10\n",
    "INVESTMENT_AMOUNT = 1000\n",
    "\n",
    "# Path configuration - adjust for notebook location\n",
    "# Since notebook is in eda-notebooks/, go up one level to project root\n",
    "PROJECT_ROOT = Path(\"..\").resolve()  # Go up one level from eda-notebooks/\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "APP_DIR = PROJECT_ROOT / \"app\"\n",
    "\n",
    "print(\"📊 Stock Prediction Decision Making Notebook\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup paths\n",
    "if str(APP_DIR) not in sys.path:\n",
    "    sys.path.append(str(APP_DIR))\n",
    "\n",
    "print(f\"✅ Paths configured:\")\n",
    "print(f\"   Project root: {PROJECT_ROOT}\")\n",
    "print(f\"   App code: {APP_DIR}\")\n",
    "print(f\"   Artifacts: {ARTIFACTS_DIR}\")\n",
    "print(f\"   Data: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef7bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Stock Prediction Decision Making Notebook\n",
      "==================================================\n",
      "✅ Paths configured:\n",
      "   Project root: /Users/sagardhal/Desktop/Practice/personal-stock\n",
      "   App code: /Users/sagardhal/Desktop/Practice/personal-stock/app\n",
      "   Artifacts: /Users/sagardhal/Desktop/Practice/personal-stock/artifacts\n",
      "   Data: /Users/sagardhal/Desktop/Practice/personal-stock/data\n"
     ]
    }
   ],
   "source": [
    "# Stock Prediction Decision Making Notebook\n",
    "# Interactive notebook for making daily trading decisions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "TOP_N_PICKS = 10\n",
    "INVESTMENT_AMOUNT = 1000\n",
    "\n",
    "# Path configuration - adjust for notebook location\n",
    "# Since notebook is in eda-notebooks/, go up one level to project root\n",
    "PROJECT_ROOT = Path(\"..\").resolve()  # Go up one level from eda-notebooks/\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "APP_DIR = PROJECT_ROOT / \"app\"\n",
    "\n",
    "print(\"📊 Stock Prediction Decision Making Notebook\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup paths\n",
    "if str(APP_DIR) not in sys.path:\n",
    "    sys.path.append(str(APP_DIR))\n",
    "\n",
    "print(f\"✅ Paths configured:\")\n",
    "print(f\"   Project root: {PROJECT_ROOT}\")\n",
    "print(f\"   App code: {APP_DIR}\")\n",
    "print(f\"   Artifacts: {ARTIFACTS_DIR}\")\n",
    "print(f\"   Data: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08407a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go up one level to the root directory\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "\n",
    "\n",
    "# # add project root (parent of notebooks/) to sys.path\n",
    "# project_root = Path.cwd().parent\n",
    "# sys.path.insert(0, str(project_root))\n",
    "\n",
    "from app.predictions import (\n",
    "    load_latest_data,\n",
    "    load_model_and_features,\n",
    "    PredictionComparator,\n",
    "    _TransformAdapter,\n",
    ")\n",
    "\n",
    "# If you also need TrainModel directly in the notebook:\n",
    "from app.train_model_new import TrainModel   # ✅ absolute package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49c429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a87c1396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 1: LOAD TICKERS\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>avg_traded_value</th>\n",
       "      <th>last_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>3.020233e+10</td>\n",
       "      <td>170.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2.744823e+10</td>\n",
       "      <td>334.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.235771e+10</td>\n",
       "      <td>238.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>1.214248e+10</td>\n",
       "      <td>154.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>1.116371e+10</td>\n",
       "      <td>505.350006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  avg_traded_value  last_close\n",
       "0   NVDA      3.020233e+10  170.619995\n",
       "1   TSLA      2.744823e+10  334.089996\n",
       "2   AAPL      1.235771e+10  238.470001\n",
       "3   PLTR      1.214248e+10  154.899994\n",
       "4   MSFT      1.116371e+10  505.350006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load Tickers\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 1: LOAD TICKERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "tickers = pd.read_csv(\"/Users/sagardhal/Desktop/Practice/personal-stock/ticker/spx_ndx_liq_top250_latest.csv\")\n",
    "tickers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3379b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 2: CHECK REQUIREMENTS\n",
      "==================================================\n",
      "🤖 Models found: 5\n",
      "   - best_rf_model.joblib\n",
      "   - random_forest_train_valid_20250904_112953.joblib\n",
      "   - random_forest_train_only_20250904_000839.joblib\n",
      "   - random_forest_train_only_20250904_112906.joblib\n",
      "   - random_forest_train_valid_20250904_000856.joblib\n",
      "📊 Data files found: 1\n",
      "   - stock_data_combined_20250904_071145.parquet\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check Requirements\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: CHECK REQUIREMENTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for trained models\n",
    "artifacts_files = list(ARTIFACTS_DIR.glob(\"*.joblib\")) + list(ARTIFACTS_DIR.glob(\"*.pkl\"))\n",
    "print(f\"🤖 Models found: {len(artifacts_files)}\")\n",
    "for f in artifacts_files:\n",
    "    print(f\"   - {f.name}\")\n",
    "\n",
    "# Check for data files\n",
    "data_files = list(DATA_DIR.glob(\"*.parquet\")) if DATA_DIR.exists() else []\n",
    "print(f\"📊 Data files found: {len(data_files)}\")\n",
    "for f in data_files[:3]:\n",
    "    print(f\"   - {f.name}\")\n",
    "if len(data_files) > 3:\n",
    "    print(f\"   ... and {len(data_files) - 3} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58fdd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 3: LOAD DATA AND MODEL\n",
      "==================================================\n",
      "[load_latest_data] Using: stock_data_combined_20250904_071145.parquet  (from /Users/sagardhal/Desktop/Practice/personal-stock/data)\n",
      "✅ Data loaded: 2,094,565 rows × 222 columns\n",
      "   Date range: 1962-01-02 00:00:00 to 2025-09-03 00:00:00\n",
      "   Unique tickers: 250\n",
      "Preparing dataframe for modeling...\n",
      "Defining feature sets...\n",
      "Feature Set Summary:\n",
      "  Growth features: 70\n",
      "  Technical indicators: 56\n",
      "  Technical patterns: 61\n",
      "  Custom numerical: 7\n",
      "  Macro features: 75\n",
      "  Categorical (for dummies): 7\n",
      "  Target columns: 2\n",
      "  Total numerical features: 206\n",
      "  Unused columns: 0\n",
      "Creating dummy variables...\n",
      "Created 397 dummy variables\n",
      "Sample dummies: ['month_1', 'month_10', 'month_11', 'month_12', 'month_2']\n",
      "Filtered data from 2000-01-01\n",
      "Date range: 2000-01-03 00:00:00 to 2025-09-03 00:00:00\n",
      "Temporal split created:\n",
      "  train: 904,317 samples\n",
      "  validation: 230,530 samples\n",
      "  test: 237,417 samples\n",
      "Creating ML datasets...\n",
      "Total features before filtering: 603\n",
      "  - Numerical: 206\n",
      "  - Dummies: 397\n",
      "Features after removing 'future': 603\n",
      "Selected target: is_positive_growth_30d_future\n",
      "ML Dataset Summary:\n",
      "  Features used: 603\n",
      "  Train: 904,317 samples\n",
      "  Validation: 230,530 samples\n",
      "  Test: 237,417 samples\n",
      "  Train+Valid: 1,134,847 samples\n",
      "  Target: is_positive_growth_30d_future\n",
      "  Target distribution (train): {1: 529807, 0: 374510}\n",
      "   Data prepared: (1372264, 620)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: LOAD DATA AND MODEL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    data = load_latest_data()\n",
    "    print(f\"✅ Data loaded: {data.shape[0]:,} rows × {data.shape[1]:,} columns\")\n",
    "    print(f\"   Date range: {data['Date'].min()} to {data['Date'].max()}\")\n",
    "    print(f\"   Unique tickers: {data['Ticker'].nunique()}\")\n",
    "    \n",
    "    # Prepare data for modeling\n",
    "    tm = TrainModel(_TransformAdapter(data))\n",
    "    tm.prepare_dataframe(start_date=\"2000-01-01\")\n",
    "    print(f\"   Data prepared: {tm.df_full.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Data loading failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48bf727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_model_and_features] Using model file: best_rf_model.joblib\n",
      "[load_model_and_features] feature_names_in_: 603 features\n",
      "✅ Model loaded successfully\n",
      "   Features: 603\n",
      "   Target: is_positive_growth_30d_future\n",
      "   Feature coverage: 100.0% (603/603)\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "try:\n",
    "    model, feature_cols, target_col = load_model_and_features(str(ARTIFACTS_DIR))\n",
    "    tm.model = model\n",
    "    tm._inference_feature_columns = feature_cols\n",
    "    if target_col:\n",
    "        tm.target_col = target_col\n",
    "    \n",
    "    print(f\"✅ Model loaded successfully\")\n",
    "    print(f\"   Features: {len(feature_cols)}\")\n",
    "    print(f\"   Target: {tm.target_col}\")\n",
    "    \n",
    "    # Check feature availability\n",
    "    available_features = [f for f in feature_cols if f in tm.df_full.columns]\n",
    "    missing_features = [f for f in feature_cols if f not in tm.df_full.columns]\n",
    "    \n",
    "    feature_coverage = len(available_features) / len(feature_cols)\n",
    "    print(f\"   Feature coverage: {feature_coverage:.1%} ({len(available_features)}/{len(feature_cols)})\")\n",
    "    \n",
    "    if feature_coverage < 0.8:\n",
    "        print(f\"⚠️ Warning: Low feature coverage ({feature_coverage:.1%})\")\n",
    "        print(\"Model and data may be incompatible\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Model loading failed: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70dabd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 4: GENERATE PREDICTIONS\n",
      "==================================================\n",
      "Creating manual rule-based predictions...\n",
      "Manual prediction summary:\n",
      "  pred0_manual_cci: 2.5% positive predictions\n",
      "  pred1_manual_prev_g1: 58.2% positive predictions\n",
      "  pred2_manual_prev_g1_and_snp: 0.0% positive predictions\n",
      "  pred3_manual_declining_rates: 47.6% positive predictions\n",
      "  pred4_manual_fed_easing: 40.5% positive predictions\n",
      "  pred5_manual_vix_contrarian: 18.9% positive predictions\n",
      "  pred6_manual_stock_btc_momentum: 0.2% positive predictions\n",
      "✅ Manual predictions created\n",
      "[add_ml_predictions] Non-finite detected in: ['growth_1d', 'growth_3d', 'growth_7d', 'growth_30d', 'growth_90d', 'growth_252d', 'growth_365d', 'growth_btc_1d', 'growth_btc_3d', 'growth_btc_7d', 'growth_btc_30d', 'growth_btc_90d']...\n",
      "ML prediction summary:\n",
      "  pred10_rf_thresh_21: 100.0% positive predictions\n",
      "  pred11_rf_thresh_50: 92.6% positive predictions\n",
      "  pred12_rf_thresh_65: 20.4% positive predictions\n",
      "  pred13_rf_thresh_80: 2.1% positive predictions\n",
      "  pred14_rf_thresh_90: 0.1% positive predictions\n",
      "✅ ML predictions created\n",
      "[auto-threshold] pred15_rf_auto_rate_1p: thr=0.884 | val rate=1.00% | test rate=0.00%\n",
      "[auto-threshold] pred15_rf_auto_rate_3p: thr=0.839 | val rate=3.00% | test rate=0.25%\n",
      "[auto-threshold] pred15_rf_auto_rate_5p: thr=0.798 | val rate=5.00% | test rate=1.73%\n",
      "✅ Adaptive thresholds created\n",
      "[Top-3 daily] pred30_top3_daily: test prediction rate ~1.22%\n",
      "[Top-5 daily] pred30_top5_daily: test prediction rate ~2.03%\n",
      "✅ Top-K strategies created\n",
      "📊 Total strategies created: 17\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Generate Predictions (only if everything loaded)\n",
    "#if not missing_requirements and 'tm' in locals() and 'model' in locals():\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: GENERATE PREDICTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create prediction comparator\n",
    "comparator = PredictionComparator(tm.df_full, tm.target_col)\n",
    "\n",
    "# Add manual rule-based predictions\n",
    "try:\n",
    "    comparator.add_manual_predictions()\n",
    "    print(\"✅ Manual predictions created\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Manual predictions failed: {e}\")\n",
    "\n",
    "# Add ML predictions\n",
    "try:\n",
    "    comparator.add_ml_predictions(model, feature_cols)\n",
    "    print(\"✅ ML predictions created\")\n",
    "    ml_success = True\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ ML predictions failed: {e}\")\n",
    "    # Create fallback probability column\n",
    "    comparator.df['rf_prob_30d'] = 0.5\n",
    "    ml_success = False\n",
    "\n",
    "# Add additional strategies if ML worked\n",
    "if ml_success and 'rf_prob_30d' in comparator.df.columns:\n",
    "    try:\n",
    "        comparator.add_ml_thresholds_from_validation(\"rf_prob_30d\")\n",
    "        print(\"✅ Adaptive thresholds created\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Adaptive thresholds failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        comparator.add_daily_topn(proba_col=\"rf_prob_30d\", n=3)\n",
    "        comparator.add_daily_topn(proba_col=\"rf_prob_30d\", n=5)\n",
    "        print(\"✅ Top-K strategies created\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Top-K strategies failed: {e}\")\n",
    "\n",
    "print(f\"📊 Total strategies created: {len(comparator.prediction_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d54bdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 5: ANALYZE YOUR TICKERS\n",
      "==================================================\n",
      "📅 Latest data date: 2025-09-03 00:00:00\n",
      "📊 Your tickers in recent data: 0/250\n",
      "❌ No data found for your tickers in recent period\n",
      "Your tickers might not be in the processed dataset\n",
      "Available tickers (sample): AAPL, ADBE, AMAT, AMD, AMZN, APP, AVGO, BA, BAC, BRK-B, C, CAT, COIN, COST, CRM, CRWD, CSCO, CVX, GEV, GOOG\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: ANALYZE YOUR TICKERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get latest date and filter to your tickers\n",
    "latest_date = comparator.df['Date'].max()\n",
    "print(f\"📅 Latest data date: {latest_date}\")\n",
    "\n",
    "# Filter to your tickers and recent data\n",
    "your_data = comparator.df[\n",
    "    (comparator.df['Ticker'].isin(tickers)) & \n",
    "    (comparator.df['Date'] >= latest_date - timedelta(days=7))\n",
    "].copy()\n",
    "\n",
    "print(f\"📊 Your tickers in recent data: {your_data['Ticker'].nunique()}/{len(tickers)}\")\n",
    "\n",
    "if len(your_data) == 0:\n",
    "    print(\"❌ No data found for your tickers in recent period\")\n",
    "    print(\"Your tickers might not be in the processed dataset\")\n",
    "    available_tickers = comparator.df['Ticker'].unique()[:20]\n",
    "    print(f\"Available tickers (sample): {', '.join(available_tickers)}\")\n",
    "else:\n",
    "    # Get most recent data for each ticker\n",
    "    latest_by_ticker = your_data.loc[your_data.groupby('Ticker')['Date'].idxmax()]\n",
    "    \n",
    "    # Sort by prediction probability\n",
    "    prob_col = 'rf_prob_30d' if 'rf_prob_30d' in latest_by_ticker.columns else None\n",
    "    if prob_col and latest_by_ticker[prob_col].std() > 0:\n",
    "        latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "        prob_source = \"ML Model\"\n",
    "    else:\n",
    "        # Fallback to manual prediction\n",
    "        manual_cols = [c for c in latest_by_ticker.columns if c.startswith('pred') and 'manual' in c]\n",
    "        if manual_cols:\n",
    "            prob_col = manual_cols[0]\n",
    "            latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "            prob_source = \"Manual Rules\"\n",
    "        else:\n",
    "            prob_col = None\n",
    "            prob_source = \"None\"\n",
    "    \n",
    "    # Top picks\n",
    "    top_picks = latest_by_ticker.head(TOP_N_PICKS)\n",
    "    \n",
    "    print(f\"\\n🎯 TOP {len(top_picks)} PICKS (sorted by {prob_source}):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, (_, stock) in enumerate(top_picks.iterrows(), 1):\n",
    "        ticker = stock['Ticker']\n",
    "        date = stock['Date'].strftime('%Y-%m-%d')\n",
    "        \n",
    "        if prob_col and prob_col == 'rf_prob_30d':\n",
    "            prob_value = f\"{stock[prob_col]*100:.1f}%\"\n",
    "        elif prob_col:\n",
    "            prob_value = f\"{stock[prob_col]:.0f}\"\n",
    "        else:\n",
    "            prob_value = \"N/A\"\n",
    "        \n",
    "        print(f\"{i:2d}. {ticker:6s} | Prob: {prob_value:6s} | Date: {date} | Investment: ${INVESTMENT_AMOUNT:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e3f6a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 5: ANALYZE YOUR TICKERS\n",
      "==================================================\n",
      "📅 Latest data date: 2025-09-03 00:00:00\n",
      "📊 Your tickers in recent data: 0/250\n",
      "❌ No data found for your tickers in recent period\n",
      "Your tickers might not be in the processed dataset\n",
      "Available tickers (sample): AAPL, ADBE, AMAT, AMD, AMZN, APP, AVGO, BA, BAC, BRK-B, C, CAT, COIN, COST, CRM, CRWD, CSCO, CVX, GEV, GOOG\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Analyze Your Tickers\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: ANALYZE YOUR TICKERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get latest date and filter to your tickers\n",
    "latest_date = comparator.df['Date'].max()\n",
    "print(f\"📅 Latest data date: {latest_date}\")\n",
    "\n",
    "# Filter to your tickers and recent data\n",
    "your_data = comparator.df[\n",
    "    (comparator.df['Ticker'].isin(tickers)) & \n",
    "    (comparator.df['Date'] >= latest_date - timedelta(days=7))\n",
    "].copy()\n",
    "\n",
    "print(f\"📊 Your tickers in recent data: {your_data['Ticker'].nunique()}/{len(tickers)}\")\n",
    "\n",
    "if len(your_data) == 0:\n",
    "    print(\"❌ No data found for your tickers in recent period\")\n",
    "    print(\"Your tickers might not be in the processed dataset\")\n",
    "    available_tickers = comparator.df['Ticker'].unique()[:20]\n",
    "    print(f\"Available tickers (sample): {', '.join(available_tickers)}\")\n",
    "else:\n",
    "    # Get most recent data for each ticker\n",
    "    latest_by_ticker = your_data.loc[your_data.groupby('Ticker')['Date'].idxmax()]\n",
    "    \n",
    "    # Sort by prediction probability\n",
    "    prob_col = 'rf_prob_30d' if 'rf_prob_30d' in latest_by_ticker.columns else None\n",
    "    if prob_col and latest_by_ticker[prob_col].std() > 0:\n",
    "        latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "        prob_source = \"ML Model\"\n",
    "    else:\n",
    "        # Fallback to manual prediction\n",
    "        manual_cols = [c for c in latest_by_ticker.columns if c.startswith('pred') and 'manual' in c]\n",
    "        if manual_cols:\n",
    "            prob_col = manual_cols[0]\n",
    "            latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "            prob_source = \"Manual Rules\"\n",
    "        else:\n",
    "            prob_col = None\n",
    "            prob_source = \"None\"\n",
    "    \n",
    "    # Top picks\n",
    "    top_picks = latest_by_ticker.head(TOP_N_PICKS)\n",
    "    \n",
    "    print(f\"\\n🎯 TOP {len(top_picks)} PICKS (sorted by {prob_source}):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, (_, stock) in enumerate(top_picks.iterrows(), 1):\n",
    "        ticker = stock['Ticker']\n",
    "        date = stock['Date'].strftime('%Y-%m-%d')\n",
    "        \n",
    "        if prob_col and prob_col == 'rf_prob_30d':\n",
    "            prob_value = f\"{stock[prob_col]*100:.1f}%\"\n",
    "        elif prob_col:\n",
    "            prob_value = f\"{stock[prob_col]:.0f}\"\n",
    "        else:\n",
    "            prob_value = \"N/A\"\n",
    "        \n",
    "        print(f\"{i:2d}. {ticker:6s} | Prob: {prob_value:6s} | Date: {date} | Investment: ${INVESTMENT_AMOUNT:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d316414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 6: DECISION MATRIX\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_picks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m total_strong_buy = \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m total_buy = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, stock \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtop_picks\u001b[49m.iterrows():\n\u001b[32m     11\u001b[39m     ticker = stock[\u001b[33m'\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Determine probability and action\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'top_picks' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 6: Decision Matrix\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 6: DECISION MATRIX\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "decisions = []\n",
    "total_strong_buy = 0\n",
    "total_buy = 0\n",
    "\n",
    "for _, stock in top_picks.iterrows():\n",
    "    ticker = stock['Ticker']\n",
    "    \n",
    "    # Determine probability and action\n",
    "    if prob_col == 'rf_prob_30d':\n",
    "        prob = stock[prob_col]\n",
    "        prob_display = f\"{prob*100:.1f}%\"\n",
    "        \n",
    "        if prob >= 0.8:\n",
    "            action = \"🟢 STRONG BUY\"\n",
    "            total_strong_buy += 1\n",
    "        elif prob >= 0.7:\n",
    "            action = \"🟡 BUY\"\n",
    "            total_buy += 1\n",
    "        elif prob >= 0.6:\n",
    "            action = \"🟠 CONSIDER\"\n",
    "        else:\n",
    "            action = \"🔴 WAIT\"\n",
    "    else:\n",
    "        prob_display = \"Manual\"\n",
    "        action = \"🟡 BUY\" if stock.get(prob_col, 0) > 0 else \"🔴 WAIT\"\n",
    "        if action == \"🟡 BUY\":\n",
    "            total_buy += 1\n",
    "    \n",
    "    decisions.append({\n",
    "        'Rank': len(decisions) + 1,\n",
    "        'Ticker': ticker,\n",
    "        'Signal': prob_display,\n",
    "        'Action': action,\n",
    "        'Investment': f\"${INVESTMENT_AMOUNT:,}\"\n",
    "    })\n",
    "\n",
    "# Display decision table\n",
    "decision_df = pd.DataFrame(decisions)\n",
    "print(decision_df.to_string(index=False))\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n💰 INVESTMENT SUMMARY:\")\n",
    "print(f\"   Strong Buy signals: {total_strong_buy}\")\n",
    "print(f\"   Buy signals: {total_buy}\")\n",
    "total_positions = total_strong_buy + total_buy\n",
    "total_investment = total_positions * INVESTMENT_AMOUNT\n",
    "print(f\"   Total positions: {total_positions}\")\n",
    "print(f\"   Total investment: ${total_investment:,}\")\n",
    "\n",
    "# Action plan\n",
    "print(f\"\\n📋 ACTION PLAN:\")\n",
    "strong_buys = [d['Ticker'] for d in decisions if 'STRONG' in d['Action']]\n",
    "buys = [d['Ticker'] for d in decisions if d['Action'] == '🟡 BUY']\n",
    "\n",
    "if strong_buys:\n",
    "    print(f\"🟢 IMMEDIATE: Buy {', '.join(strong_buys)}\")\n",
    "if buys:\n",
    "    print(f\"🟡 SECONDARY: Consider {', '.join(buys)}\")\n",
    "if not strong_buys and not buys:\n",
    "    print(\"🔴 WAIT: No strong signals today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save Results\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 7: SAVE RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Save with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "results_file = RESULTS_DIR / f\"notebook_decisions_{timestamp}.csv\"\n",
    "\n",
    "# Create tracking dataframe\n",
    "tracking_df = pd.DataFrame(decisions)\n",
    "tracking_df['Analysis_Date'] = datetime.now()\n",
    "tracking_df['Data_Date'] = latest_date\n",
    "tracking_df['Model_Source'] = prob_source\n",
    "tracking_df['Ticker_Count'] = len(tickers)\n",
    "\n",
    "# Save\n",
    "tracking_df.to_csv(results_file, index=False)\n",
    "print(f\"💾 Results saved: {results_file}\")\n",
    "\n",
    "# Also save just the buy signals for easy reference\n",
    "buy_signals = tracking_df[tracking_df['Action'].str.contains('BUY')]\n",
    "if len(buy_signals) > 0:\n",
    "    buy_file = RESULTS_DIR / f\"buy_signals_{timestamp}.csv\"\n",
    "    buy_signals[['Ticker', 'Action', 'Investment']].to_csv(buy_file, index=False)\n",
    "    print(f\"💾 Buy signals saved: {buy_file}\")\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if missing_requirements:\n",
    "print(\"❌ Analysis incomplete due to missing requirements\")\n",
    "print(\"Complete the setup steps above and restart\")\n",
    "elif 'decisions' in locals():\n",
    "print(\"✅ Analysis complete!\")\n",
    "print(f\"📊 Analyzed {len(top_picks)} stocks from {len(tickers)} tickers\")\n",
    "print(f\"💰 Investment recommendations: ${total_investment:,}\")\n",
    "print(f\"📅 Based on data through: {latest_date}\")\n",
    "\n",
    "print(f\"\\n🔄 To refresh analysis:\")\n",
    "print(\"1. Update data: python run_data_extraction.py\")\n",
    "print(\"2. Retrain model (optional): python run_model_training.py\")\n",
    "print(\"3. Re-run this notebook\")\n",
    "else:\n",
    "print(\"⚠️ Analysis incomplete - check errors above\")\n",
    "\n",
    "print(f\"\\n📝 Remember:\")\n",
    "print(\"• Set stop losses at -15% to -20%\")\n",
    "print(\"• Monitor positions daily\")\n",
    "print(\"• Diversify - don't put more than 5-10% in any single position\")\n",
    "print(\"• Past performance doesn't guarantee future results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
