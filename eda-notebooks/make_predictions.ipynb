{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20f6a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Stock Prediction Decision Making Notebook\n",
      "==================================================\n",
      "‚úÖ Paths configured:\n",
      "   Project root: /Users/sagardhal/Desktop/Practice/personal-stock\n",
      "   App code: /Users/sagardhal/Desktop/Practice/personal-stock/app\n",
      "   Artifacts: /Users/sagardhal/Desktop/Practice/personal-stock/artifacts\n",
      "   Data: /Users/sagardhal/Desktop/Practice/personal-stock/data\n"
     ]
    }
   ],
   "source": [
    "# Stock Prediction Decision Making Notebook\n",
    "# Interactive notebook for making daily trading decisions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "TOP_N_PICKS = 10\n",
    "INVESTMENT_AMOUNT = 1000\n",
    "\n",
    "# Path configuration - adjust for notebook location\n",
    "# Since notebook is in eda-notebooks/, go up one level to project root\n",
    "PROJECT_ROOT = Path(\"..\").resolve()  # Go up one level from eda-notebooks/\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "APP_DIR = PROJECT_ROOT / \"app\"\n",
    "\n",
    "print(\"üìä Stock Prediction Decision Making Notebook\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup paths\n",
    "if str(APP_DIR) not in sys.path:\n",
    "    sys.path.append(str(APP_DIR))\n",
    "\n",
    "print(f\"‚úÖ Paths configured:\")\n",
    "print(f\"   Project root: {PROJECT_ROOT}\")\n",
    "print(f\"   App code: {APP_DIR}\")\n",
    "print(f\"   Artifacts: {ARTIFACTS_DIR}\")\n",
    "print(f\"   Data: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ef7bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Stock Prediction Decision Making Notebook\n",
      "==================================================\n",
      "‚úÖ Paths configured:\n",
      "   Project root: /Users/sagardhal/Desktop/Practice/personal-stock\n",
      "   App code: /Users/sagardhal/Desktop/Practice/personal-stock/app\n",
      "   Artifacts: /Users/sagardhal/Desktop/Practice/personal-stock/artifacts\n",
      "   Data: /Users/sagardhal/Desktop/Practice/personal-stock/data\n"
     ]
    }
   ],
   "source": [
    "# Stock Prediction Decision Making Notebook\n",
    "# Interactive notebook for making daily trading decisions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "TOP_N_PICKS = 10\n",
    "INVESTMENT_AMOUNT = 1000\n",
    "\n",
    "# Path configuration - adjust for notebook location\n",
    "# Since notebook is in eda-notebooks/, go up one level to project root\n",
    "PROJECT_ROOT = Path(\"..\").resolve()  # Go up one level from eda-notebooks/\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "APP_DIR = PROJECT_ROOT / \"app\"\n",
    "\n",
    "print(\"üìä Stock Prediction Decision Making Notebook\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup paths\n",
    "if str(APP_DIR) not in sys.path:\n",
    "    sys.path.append(str(APP_DIR))\n",
    "\n",
    "print(f\"‚úÖ Paths configured:\")\n",
    "print(f\"   Project root: {PROJECT_ROOT}\")\n",
    "print(f\"   App code: {APP_DIR}\")\n",
    "print(f\"   Artifacts: {ARTIFACTS_DIR}\")\n",
    "print(f\"   Data: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08407a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go up one level to the root directory\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "\n",
    "\n",
    "# # add project root (parent of notebooks/) to sys.path\n",
    "# project_root = Path.cwd().parent\n",
    "# sys.path.insert(0, str(project_root))\n",
    "\n",
    "from app.predictions import (\n",
    "    load_latest_data,\n",
    "    load_model_and_features,\n",
    "    PredictionComparator,\n",
    "    _TransformAdapter,\n",
    ")\n",
    "\n",
    "# If you also need TrainModel directly in the notebook:\n",
    "from app.train_model_new import TrainModel   # ‚úÖ absolute package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49c429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87c1396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 1: LOAD TICKERS\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>avg_traded_value</th>\n",
       "      <th>last_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>3.020233e+10</td>\n",
       "      <td>170.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2.744823e+10</td>\n",
       "      <td>334.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.235771e+10</td>\n",
       "      <td>238.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>1.214248e+10</td>\n",
       "      <td>154.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>1.116371e+10</td>\n",
       "      <td>505.350006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  avg_traded_value  last_close\n",
       "0   NVDA      3.020233e+10  170.619995\n",
       "1   TSLA      2.744823e+10  334.089996\n",
       "2   AAPL      1.235771e+10  238.470001\n",
       "3   PLTR      1.214248e+10  154.899994\n",
       "4   MSFT      1.116371e+10  505.350006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load Tickers\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 1: LOAD TICKERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "tickers = pd.read_csv(\"/Users/sagardhal/Desktop/Practice/personal-stock/ticker/spx_ndx_liq_top250_latest.csv\")\n",
    "tickers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3379b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 2: CHECK REQUIREMENTS\n",
      "==================================================\n",
      "ü§ñ Models found: 5\n",
      "   - best_rf_model.joblib\n",
      "   - random_forest_train_valid_20250904_112953.joblib\n",
      "   - random_forest_train_only_20250904_000839.joblib\n",
      "   - random_forest_train_only_20250904_112906.joblib\n",
      "   - random_forest_train_valid_20250904_000856.joblib\n",
      "üìä Data files found: 1\n",
      "   - stock_data_combined_20250904_071145.parquet\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check Requirements\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: CHECK REQUIREMENTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for trained models\n",
    "artifacts_files = list(ARTIFACTS_DIR.glob(\"*.joblib\")) + list(ARTIFACTS_DIR.glob(\"*.pkl\"))\n",
    "print(f\"ü§ñ Models found: {len(artifacts_files)}\")\n",
    "for f in artifacts_files:\n",
    "    print(f\"   - {f.name}\")\n",
    "\n",
    "# Check for data files\n",
    "data_files = list(DATA_DIR.glob(\"*.parquet\")) if DATA_DIR.exists() else []\n",
    "print(f\"üìä Data files found: {len(data_files)}\")\n",
    "for f in data_files[:3]:\n",
    "    print(f\"   - {f.name}\")\n",
    "if len(data_files) > 3:\n",
    "    print(f\"   ... and {len(data_files) - 3} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d58fdd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 3: LOAD DATA AND MODEL\n",
      "==================================================\n",
      "[load_latest_data] Using: stock_data_combined_20250904_071145.parquet  (from /Users/sagardhal/Desktop/Practice/personal-stock/data)\n",
      "‚úÖ Data loaded: 2,094,565 rows √ó 222 columns\n",
      "   Date range: 1962-01-02 00:00:00 to 2025-09-03 00:00:00\n",
      "   Unique tickers: 250\n",
      "Preparing dataframe for modeling...\n",
      "Defining feature sets...\n",
      "Feature Set Summary:\n",
      "  Growth features: 70\n",
      "  Technical indicators: 56\n",
      "  Technical patterns: 61\n",
      "  Custom numerical: 7\n",
      "  Macro features: 75\n",
      "  Categorical (for dummies): 7\n",
      "  Target columns: 2\n",
      "  Total numerical features: 206\n",
      "  Unused columns: 0\n",
      "Creating dummy variables...\n",
      "Created 397 dummy variables\n",
      "Sample dummies: ['month_1', 'month_10', 'month_11', 'month_12', 'month_2']\n",
      "Filtered data from 2000-01-01\n",
      "Date range: 2000-01-03 00:00:00 to 2025-09-03 00:00:00\n",
      "Temporal split created:\n",
      "  train: 904,317 samples\n",
      "  validation: 230,530 samples\n",
      "  test: 237,417 samples\n",
      "Creating ML datasets...\n",
      "Total features before filtering: 603\n",
      "  - Numerical: 206\n",
      "  - Dummies: 397\n",
      "Features after removing 'future': 603\n",
      "Selected target: is_positive_growth_30d_future\n",
      "ML Dataset Summary:\n",
      "  Features used: 603\n",
      "  Train: 904,317 samples\n",
      "  Validation: 230,530 samples\n",
      "  Test: 237,417 samples\n",
      "  Train+Valid: 1,134,847 samples\n",
      "  Target: is_positive_growth_30d_future\n",
      "  Target distribution (train): {1: 529807, 0: 374510}\n",
      "   Data prepared: (1372264, 620)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: LOAD DATA AND MODEL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    data = load_latest_data()\n",
    "    print(f\"‚úÖ Data loaded: {data.shape[0]:,} rows √ó {data.shape[1]:,} columns\")\n",
    "    print(f\"   Date range: {data['Date'].min()} to {data['Date'].max()}\")\n",
    "    print(f\"   Unique tickers: {data['Ticker'].nunique()}\")\n",
    "    \n",
    "    # Prepare data for modeling\n",
    "    tm = TrainModel(_TransformAdapter(data))\n",
    "    tm.prepare_dataframe(start_date=\"2000-01-01\")\n",
    "    print(f\"   Data prepared: {tm.df_full.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data loading failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48bf727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_model_and_features] Using model file: best_rf_model.joblib\n",
      "[load_model_and_features] feature_names_in_: 603 features\n",
      "‚úÖ Model loaded successfully\n",
      "   Features: 603\n",
      "   Target: is_positive_growth_30d_future\n",
      "   Feature coverage: 100.0% (603/603)\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "try:\n",
    "    model, feature_cols, target_col = load_model_and_features(str(ARTIFACTS_DIR))\n",
    "    tm.model = model\n",
    "    tm._inference_feature_columns = feature_cols\n",
    "    if target_col:\n",
    "        tm.target_col = target_col\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully\")\n",
    "    print(f\"   Features: {len(feature_cols)}\")\n",
    "    print(f\"   Target: {tm.target_col}\")\n",
    "    \n",
    "    # Check feature availability\n",
    "    available_features = [f for f in feature_cols if f in tm.df_full.columns]\n",
    "    missing_features = [f for f in feature_cols if f not in tm.df_full.columns]\n",
    "    \n",
    "    feature_coverage = len(available_features) / len(feature_cols)\n",
    "    print(f\"   Feature coverage: {feature_coverage:.1%} ({len(available_features)}/{len(feature_cols)})\")\n",
    "    \n",
    "    if feature_coverage < 0.8:\n",
    "        print(f\"‚ö†Ô∏è Warning: Low feature coverage ({feature_coverage:.1%})\")\n",
    "        print(\"Model and data may be incompatible\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model loading failed: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70dabd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 4: GENERATE PREDICTIONS\n",
      "==================================================\n",
      "Creating manual rule-based predictions...\n",
      "Manual prediction summary:\n",
      "  pred0_manual_cci: 2.5% positive predictions\n",
      "  pred1_manual_prev_g1: 58.2% positive predictions\n",
      "  pred2_manual_prev_g1_and_snp: 0.0% positive predictions\n",
      "  pred3_manual_declining_rates: 47.6% positive predictions\n",
      "  pred4_manual_fed_easing: 40.5% positive predictions\n",
      "  pred5_manual_vix_contrarian: 18.9% positive predictions\n",
      "  pred6_manual_stock_btc_momentum: 0.2% positive predictions\n",
      "‚úÖ Manual predictions created\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Add ML predictions\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mcomparator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_ml_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ ML predictions created\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     ml_success = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practice/personal-stock/app/predictions.py:343\u001b[39m, in \u001b[36mPredictionComparator.add_ml_predictions\u001b[39m\u001b[34m(self, model, feature_cols, thresholds)\u001b[39m\n\u001b[32m    336\u001b[39m X = pd.DataFrame(\n\u001b[32m    337\u001b[39m     {c: (pd.to_numeric(\u001b[38;5;28mself\u001b[39m.df[c], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.df.columns \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m)\n\u001b[32m    338\u001b[39m      \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m feature_cols},\n\u001b[32m    339\u001b[39m     index=\u001b[38;5;28mself\u001b[39m.df.index,\n\u001b[32m    340\u001b[39m )\n\u001b[32m    342\u001b[39m \u001b[38;5;66;03m# 2) Sanitize non-finites\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m arr = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(arr).all():\n\u001b[32m    345\u001b[39m     bad_cols = X.columns[~np.isfinite(arr).all(axis=\u001b[32m0\u001b[39m)].tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practice/personal-stock/.venv/lib/python3.13/site-packages/pandas/core/frame.py:1998\u001b[39m, in \u001b[36mDataFrame.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1996\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1997\u001b[39m     dtype = np.dtype(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1998\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1999\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[32m   2000\u001b[39m     result = np.asarray(result, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practice/personal-stock/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:1694\u001b[39m, in \u001b[36mBlockManager.as_array\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1692\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[32m   1696\u001b[39m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practice/personal-stock/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:1754\u001b[39m, in \u001b[36mBlockManager._interleave\u001b[39m\u001b[34m(self, dtype, na_value)\u001b[39m\n\u001b[32m   1752\u001b[39m         arr = blk.get_values(dtype)\n\u001b[32m   1753\u001b[39m     result[rl.indexer] = arr\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m     itemmask[rl.indexer] = \u001b[32m1\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask.all():\n\u001b[32m   1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSome items were not contained in blocks\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Step 4: Generate Predictions (only if everything loaded)\n",
    "#if not missing_requirements and 'tm' in locals() and 'model' in locals():\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: GENERATE PREDICTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create prediction comparator\n",
    "comparator = PredictionComparator(tm.df_full, tm.target_col)\n",
    "\n",
    "# Add manual rule-based predictions\n",
    "try:\n",
    "    comparator.add_manual_predictions()\n",
    "    print(\"‚úÖ Manual predictions created\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Manual predictions failed: {e}\")\n",
    "\n",
    "# Add ML predictions\n",
    "try:\n",
    "    comparator.add_ml_predictions(model, feature_cols)\n",
    "    print(\"‚úÖ ML predictions created\")\n",
    "    ml_success = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è ML predictions failed: {e}\")\n",
    "    # Create fallback probability column\n",
    "    comparator.df['rf_prob_30d'] = 0.5\n",
    "    ml_success = False\n",
    "\n",
    "# Add additional strategies if ML worked\n",
    "if ml_success and 'rf_prob_30d' in comparator.df.columns:\n",
    "    try:\n",
    "        comparator.add_ml_thresholds_from_validation(\"rf_prob_30d\")\n",
    "        print(\"‚úÖ Adaptive thresholds created\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Adaptive thresholds failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        comparator.add_daily_topn(proba_col=\"rf_prob_30d\", n=3)\n",
    "        comparator.add_daily_topn(proba_col=\"rf_prob_30d\", n=5)\n",
    "        print(\"‚úÖ Top-K strategies created\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Top-K strategies failed: {e}\")\n",
    "\n",
    "print(f\"üìä Total strategies created: {len(comparator.prediction_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54bdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 5: ANALYZE YOUR TICKERS\n",
      "==================================================\n",
      "üìÖ Latest data date: 2025-09-03 00:00:00\n",
      "üìä Your tickers in recent data: 0/250\n",
      "‚ùå No data found for your tickers in recent period\n",
      "Your tickers might not be in the processed dataset\n",
      "Available tickers (sample): AAPL, ADBE, AMAT, AMD, AMZN, APP, AVGO, BA, BAC, BRK-B, C, CAT, COIN, COST, CRM, CRWD, CSCO, CVX, GEV, GOOG\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: ANALYZE YOUR TICKERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get latest date and filter to your tickers\n",
    "latest_date = comparator.df['Date'].max()\n",
    "print(f\"üìÖ Latest data date: {latest_date}\")\n",
    "\n",
    "# Filter to your tickers and recent data\n",
    "your_data = comparator.df[\n",
    "    (comparator.df['Ticker'].isin(tickers)) & \n",
    "    (comparator.df['Date'] >= latest_date - timedelta(days=7))\n",
    "].copy()\n",
    "\n",
    "print(f\"üìä Your tickers in recent data: {your_data['Ticker'].nunique()}/{len(tickers)}\")\n",
    "\n",
    "if len(your_data) == 0:\n",
    "    print(\"‚ùå No data found for your tickers in recent period\")\n",
    "    print(\"Your tickers might not be in the processed dataset\")\n",
    "    available_tickers = comparator.df['Ticker'].unique()[:20]\n",
    "    print(f\"Available tickers (sample): {', '.join(available_tickers)}\")\n",
    "else:\n",
    "    # Get most recent data for each ticker\n",
    "    latest_by_ticker = your_data.loc[your_data.groupby('Ticker')['Date'].idxmax()]\n",
    "    \n",
    "    # Sort by prediction probability\n",
    "    prob_col = 'rf_prob_30d' if 'rf_prob_30d' in latest_by_ticker.columns else None\n",
    "    if prob_col and latest_by_ticker[prob_col].std() > 0:\n",
    "        latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "        prob_source = \"ML Model\"\n",
    "    else:\n",
    "        # Fallback to manual prediction\n",
    "        manual_cols = [c for c in latest_by_ticker.columns if c.startswith('pred') and 'manual' in c]\n",
    "        if manual_cols:\n",
    "            prob_col = manual_cols[0]\n",
    "            latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "            prob_source = \"Manual Rules\"\n",
    "        else:\n",
    "            prob_col = None\n",
    "            prob_source = \"None\"\n",
    "    \n",
    "    # Top picks\n",
    "    top_picks = latest_by_ticker.head(TOP_N_PICKS)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP {len(top_picks)} PICKS (sorted by {prob_source}):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, (_, stock) in enumerate(top_picks.iterrows(), 1):\n",
    "        ticker = stock['Ticker']\n",
    "        date = stock['Date'].strftime('%Y-%m-%d')\n",
    "        \n",
    "        if prob_col and prob_col == 'rf_prob_30d':\n",
    "            prob_value = f\"{stock[prob_col]*100:.1f}%\"\n",
    "        elif prob_col:\n",
    "            prob_value = f\"{stock[prob_col]:.0f}\"\n",
    "        else:\n",
    "            prob_value = \"N/A\"\n",
    "        \n",
    "        print(f\"{i:2d}. {ticker:6s} | Prob: {prob_value:6s} | Date: {date} | Investment: ${INVESTMENT_AMOUNT:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f6a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 5: ANALYZE YOUR TICKERS\n",
      "==================================================\n",
      "üìÖ Latest data date: 2025-09-03 00:00:00\n",
      "üìä Your tickers in recent data: 0/250\n",
      "‚ùå No data found for your tickers in recent period\n",
      "Your tickers might not be in the processed dataset\n",
      "Available tickers (sample): AAPL, ADBE, AMAT, AMD, AMZN, APP, AVGO, BA, BAC, BRK-B, C, CAT, COIN, COST, CRM, CRWD, CSCO, CVX, GEV, GOOG\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Analyze Your Tickers\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: ANALYZE YOUR TICKERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get latest date and filter to your tickers\n",
    "latest_date = comparator.df['Date'].max()\n",
    "print(f\"üìÖ Latest data date: {latest_date}\")\n",
    "\n",
    "# Filter to your tickers and recent data\n",
    "your_data = comparator.df[\n",
    "    (comparator.df['Ticker'].isin(tickers)) & \n",
    "    (comparator.df['Date'] >= latest_date - timedelta(days=7))\n",
    "].copy()\n",
    "\n",
    "print(f\"üìä Your tickers in recent data: {your_data['Ticker'].nunique()}/{len(tickers)}\")\n",
    "\n",
    "if len(your_data) == 0:\n",
    "    print(\"‚ùå No data found for your tickers in recent period\")\n",
    "    print(\"Your tickers might not be in the processed dataset\")\n",
    "    available_tickers = comparator.df['Ticker'].unique()[:20]\n",
    "    print(f\"Available tickers (sample): {', '.join(available_tickers)}\")\n",
    "else:\n",
    "    # Get most recent data for each ticker\n",
    "    latest_by_ticker = your_data.loc[your_data.groupby('Ticker')['Date'].idxmax()]\n",
    "    \n",
    "    # Sort by prediction probability\n",
    "    prob_col = 'rf_prob_30d' if 'rf_prob_30d' in latest_by_ticker.columns else None\n",
    "    if prob_col and latest_by_ticker[prob_col].std() > 0:\n",
    "        latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "        prob_source = \"ML Model\"\n",
    "    else:\n",
    "        # Fallback to manual prediction\n",
    "        manual_cols = [c for c in latest_by_ticker.columns if c.startswith('pred') and 'manual' in c]\n",
    "        if manual_cols:\n",
    "            prob_col = manual_cols[0]\n",
    "            latest_by_ticker = latest_by_ticker.sort_values(prob_col, ascending=False)\n",
    "            prob_source = \"Manual Rules\"\n",
    "        else:\n",
    "            prob_col = None\n",
    "            prob_source = \"None\"\n",
    "    \n",
    "    # Top picks\n",
    "    top_picks = latest_by_ticker.head(TOP_N_PICKS)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP {len(top_picks)} PICKS (sorted by {prob_source}):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, (_, stock) in enumerate(top_picks.iterrows(), 1):\n",
    "        ticker = stock['Ticker']\n",
    "        date = stock['Date'].strftime('%Y-%m-%d')\n",
    "        \n",
    "        if prob_col and prob_col == 'rf_prob_30d':\n",
    "            prob_value = f\"{stock[prob_col]*100:.1f}%\"\n",
    "        elif prob_col:\n",
    "            prob_value = f\"{stock[prob_col]:.0f}\"\n",
    "        else:\n",
    "            prob_value = \"N/A\"\n",
    "        \n",
    "        print(f\"{i:2d}. {ticker:6s} | Prob: {prob_value:6s} | Date: {date} | Investment: ${INVESTMENT_AMOUNT:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 6: DECISION MATRIX\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_picks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m total_strong_buy = \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m total_buy = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, stock \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtop_picks\u001b[49m.iterrows():\n\u001b[32m     11\u001b[39m     ticker = stock[\u001b[33m'\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Determine probability and action\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'top_picks' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 6: Decision Matrix\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 6: DECISION MATRIX\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "decisions = []\n",
    "total_strong_buy = 0\n",
    "total_buy = 0\n",
    "\n",
    "for _, stock in top_picks.iterrows():\n",
    "    ticker = stock['Ticker']\n",
    "    \n",
    "    # Determine probability and action\n",
    "    if prob_col == 'rf_prob_30d':\n",
    "        prob = stock[prob_col]\n",
    "        prob_display = f\"{prob*100:.1f}%\"\n",
    "        \n",
    "        if prob >= 0.8:\n",
    "            action = \"üü¢ STRONG BUY\"\n",
    "            total_strong_buy += 1\n",
    "        elif prob >= 0.7:\n",
    "            action = \"üü° BUY\"\n",
    "            total_buy += 1\n",
    "        elif prob >= 0.6:\n",
    "            action = \"üü† CONSIDER\"\n",
    "        else:\n",
    "            action = \"üî¥ WAIT\"\n",
    "    else:\n",
    "        prob_display = \"Manual\"\n",
    "        action = \"üü° BUY\" if stock.get(prob_col, 0) > 0 else \"üî¥ WAIT\"\n",
    "        if action == \"üü° BUY\":\n",
    "            total_buy += 1\n",
    "    \n",
    "    decisions.append({\n",
    "        'Rank': len(decisions) + 1,\n",
    "        'Ticker': ticker,\n",
    "        'Signal': prob_display,\n",
    "        'Action': action,\n",
    "        'Investment': f\"${INVESTMENT_AMOUNT:,}\"\n",
    "    })\n",
    "\n",
    "# Display decision table\n",
    "decision_df = pd.DataFrame(decisions)\n",
    "print(decision_df.to_string(index=False))\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüí∞ INVESTMENT SUMMARY:\")\n",
    "print(f\"   Strong Buy signals: {total_strong_buy}\")\n",
    "print(f\"   Buy signals: {total_buy}\")\n",
    "total_positions = total_strong_buy + total_buy\n",
    "total_investment = total_positions * INVESTMENT_AMOUNT\n",
    "print(f\"   Total positions: {total_positions}\")\n",
    "print(f\"   Total investment: ${total_investment:,}\")\n",
    "\n",
    "# Action plan\n",
    "print(f\"\\nüìã ACTION PLAN:\")\n",
    "strong_buys = [d['Ticker'] for d in decisions if 'STRONG' in d['Action']]\n",
    "buys = [d['Ticker'] for d in decisions if d['Action'] == 'üü° BUY']\n",
    "\n",
    "if strong_buys:\n",
    "    print(f\"üü¢ IMMEDIATE: Buy {', '.join(strong_buys)}\")\n",
    "if buys:\n",
    "    print(f\"üü° SECONDARY: Consider {', '.join(buys)}\")\n",
    "if not strong_buys and not buys:\n",
    "    print(\"üî¥ WAIT: No strong signals today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save Results\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 7: SAVE RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Save with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "results_file = RESULTS_DIR / f\"notebook_decisions_{timestamp}.csv\"\n",
    "\n",
    "# Create tracking dataframe\n",
    "tracking_df = pd.DataFrame(decisions)\n",
    "tracking_df['Analysis_Date'] = datetime.now()\n",
    "tracking_df['Data_Date'] = latest_date\n",
    "tracking_df['Model_Source'] = prob_source\n",
    "tracking_df['Ticker_Count'] = len(tickers)\n",
    "\n",
    "# Save\n",
    "tracking_df.to_csv(results_file, index=False)\n",
    "print(f\"üíæ Results saved: {results_file}\")\n",
    "\n",
    "# Also save just the buy signals for easy reference\n",
    "buy_signals = tracking_df[tracking_df['Action'].str.contains('BUY')]\n",
    "if len(buy_signals) > 0:\n",
    "    buy_file = RESULTS_DIR / f\"buy_signals_{timestamp}.csv\"\n",
    "    buy_signals[['Ticker', 'Action', 'Investment']].to_csv(buy_file, index=False)\n",
    "    print(f\"üíæ Buy signals saved: {buy_file}\")\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if missing_requirements:\n",
    "print(\"‚ùå Analysis incomplete due to missing requirements\")\n",
    "print(\"Complete the setup steps above and restart\")\n",
    "elif 'decisions' in locals():\n",
    "print(\"‚úÖ Analysis complete!\")\n",
    "print(f\"üìä Analyzed {len(top_picks)} stocks from {len(tickers)} tickers\")\n",
    "print(f\"üí∞ Investment recommendations: ${total_investment:,}\")\n",
    "print(f\"üìÖ Based on data through: {latest_date}\")\n",
    "\n",
    "print(f\"\\nüîÑ To refresh analysis:\")\n",
    "print(\"1. Update data: python run_data_extraction.py\")\n",
    "print(\"2. Retrain model (optional): python run_model_training.py\")\n",
    "print(\"3. Re-run this notebook\")\n",
    "else:\n",
    "print(\"‚ö†Ô∏è Analysis incomplete - check errors above\")\n",
    "\n",
    "print(f\"\\nüìù Remember:\")\n",
    "print(\"‚Ä¢ Set stop losses at -15% to -20%\")\n",
    "print(\"‚Ä¢ Monitor positions daily\")\n",
    "print(\"‚Ä¢ Diversify - don't put more than 5-10% in any single position\")\n",
    "print(\"‚Ä¢ Past performance doesn't guarantee future results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
